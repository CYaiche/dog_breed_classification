{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet152\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Input\n",
    "from common_params import data_dir, img_dir\n",
    "from common_plots import display_images\n",
    "from data_load import get_train_val_set, apply_data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsub_dir = os.path.join(data_dir,\"30_classes_all\")\n",
    "IMG_SIZE = 224\n",
    "batch_size = 32\n",
    "image_size = (IMG_SIZE, IMG_SIZE)\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning using Xception "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6164 files belonging to 30 classes.\n",
      "Using 4932 files for training.\n",
      "Using 1232 files for validation.\n",
      "WARNING:tensorflow:From c:\\dev\\image_classification\\IMG2\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "train_ds, validation_ds = get_train_val_set(imgsub_dir, image_size, batch_size)\n",
    "train_ds, validation_ds = apply_data_augmentation(train_ds, validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xception_model():\n",
    "    model = Sequential()\n",
    "    model.add(Xception(include_top=False, pooling='avg', weights=\"imagenet\"))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(120, activation='softmax'))\n",
    "    model.layers[0].trainable = False\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmodel = get_xception_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"xception-transfert-learning-dog-breed-classifier\"\n",
    "run_name = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "logdir = os.path.join(data_dir,\"logs\", experiment_name, run_name)\n",
    "tb_callback = [tf.keras.callbacks.TensorBoard(log_dir=logdir, write_graph=True, histogram_freq=1)]\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "\n",
    "xmodel.fit(x=train_ds, \n",
    "        epochs=5, \n",
    "        validation_data=validation_ds,\n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with RestNet-152\n",
    "tf.keras.applications.resnet.ResNet152 to load the ResNet-152 architecture with pre-trained ImageNet weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model() : \n",
    "    # Create an Input layer with the desired input shape\n",
    "\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Load ResNet-152 model with pre-trained ImageNet weights\n",
    "    resnet152_model = ResNet152(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=None,  # You can specify 'avg' or 'max' pooling here if needed\n",
    "        classes=1000\n",
    "    )\n",
    "\n",
    "    x = resnet152_model(inputs, training=False)\n",
    "    # Set the pooling layer\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    # Set the final layer with sigmoid activation function\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    # Create the new model object\n",
    "    model = tf.keras.Model(inputs=inputs , outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters and input data\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Define names for tensorboard logging and mlflow\n",
    "experiment_name = \"dog-breed-classifier-ResNet152\"\n",
    "run_name = datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.utils.load_img(\n",
    "    os.path.join(img_dir,\"n02085620-Chihuahua\\\\n02085620_7.jpg\"), target_size=(IMG_SIZE, IMG_SIZE)\n",
    ")\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "print(predictions)\n",
    "# score = float(predictions[0])\n",
    "# print(f\"This image is {100 * (1 - score):.2f}% cat and {100 * score:.2f}% dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logdir = os.path.join(data_dir,\"logs\", experiment_name, run_name)\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, write_graph=True, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    augmented_train_dataset ,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_ds,\n",
    "    callbacks=[tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the experiment name and create an MLflow run\n",
    "mlflow.set_experiment(experiment_name)\n",
    "with mlflow.start_run(run_name = run_name) as mlflow_run:\n",
    "    \n",
    "    mlflow.set_experiment_tag(\"base_model\", \"MobileNet\")\n",
    "    mlflow.set_tag(\"optimizer\", \"keras.optimizers.Adam\")\n",
    "    mlflow.set_tag(\"loss\", \"sparse_categorical_crossentropy\")\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"input_shape\", input_shape)\n",
    "\n",
    "    mlflow.log_metric(\"train_loss\", history.history[\"loss\"][-1])\n",
    "    mlflow.log_metric(\"train_acc\", history.history[\"accuracy\"][-1])\n",
    "    mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][-1])\n",
    "    mlflow.log_metric(\"val_acc\", history.history[\"val_accuracy\"][-1])\n",
    "\n",
    "    mlflow.log_artifact(\"model.png\", \"model_plot\")\n",
    "\n",
    "    mlflow_run_id = mlflow_run.info.run_id\n",
    "    print(\"MLFlow Run ID: \", mlflow_run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMG2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
